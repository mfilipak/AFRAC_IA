{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "002 - Embeddings1 - Portal da Transparência.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2wh/rQHn7Q8nwBaaHsG4j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfilipak/AFRAC_IA/blob/main/002_Embeddings1_Portal_da_Transpar%C3%AAncia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM CONSTRUÇÃO"
      ],
      "metadata": {
        "id": "ANdfGpMVsm6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento 002\n",
        "##Objetivo: Experimentos com word embeddings usando como corpo o campo de descrição do dataset público do portal da transparência.\n",
        "###Descrição: Experimentos iniciais para criação e visualização de word embeddings"
      ],
      "metadata": {
        "id": "d5G4UIQLkvr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dica: No COLAB Use CTRL SPACE ao invés de TAB para \"autocompletar\". Ex:pd.re [CTRL SPACE] vai mostrar uma lista contendo as funções e atributos que começam com pd.re (como read_csv, ...) "
      ],
      "metadata": {
        "id": "F9TFhfPOld7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "Nvzp4RpDlHTq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMc2HxxMGauw",
        "outputId": "7e0bf1ab-d557-439a-b9a2-ba77c7f5181f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 - Carga do dataset"
      ],
      "metadata": {
        "id": "nHAJmE8HtX7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Copia os dados das NFEs do portal da cidadância pro drive virtual.\n",
        "import requests  \n",
        "file_url = \"https://raw.githubusercontent.com//mfilipak/AFRAC_IA/main/DATASET/202201_NFe_NotaFiscalItem.zip\"\n",
        "r = requests.get(file_url, stream = True) \n",
        "\n",
        "with open(\"portal.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)\n",
        "\n",
        "DATA_FILE = \"portal.zip\"\n",
        "df = pd.read_csv(DATA_FILE, encoding=\"CP1252\",sep=\";\")\n",
        "print(\"O dataframe completo contém:\",len(df),\"linhas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tBOpT5elhBD",
        "outputId": "60e534d9-b662-4a39-9606-b18db2655611"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dataframe completo contém: 324056 linhas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df[['DATA EMISSÃO','DESCRIÇÃO DO PRODUTO/SERVIÇO', 'CÓDIGO NCM/SH', 'CFOP']]\n",
        "df3.columns = [\"DATA\", \"DESCR\", \"NCM\", \"CFOP\"]\n",
        "df3 = df3[df3[\"NCM\"]!=-1] #Filtrando NCMs = -1\n",
        "\n",
        "text_lengths = np.array([len(_) for _ in df3['DESCR']])\n",
        "df3 = df3[text_lengths>=3]\n",
        "\n",
        "#Caso queira eliminar as repetições rodar a linha abaixo\n",
        "df3 = df3.drop_duplicates(subset=[\"DESCR\"])"
      ],
      "metadata": {
        "id": "8IVtFSawlr_T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 - Carga do text corpus"
      ],
      "metadata": {
        "id": "fkOffymdtdem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No jargão do doc2vec, cada descrição é um document e o conjunto de docs um corpus\n",
        "#Link: https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html#sphx-glr-auto-examples-core-run-core-concepts-py\n",
        "random.seed(42)\n",
        "#text_corpus = random.sample(list(df3[\"DESCR\"]), 100)\n",
        "text_corpus = random.sample(list(df3[\"DESCR\"][:30]), 10)\n",
        "text_corpus\n",
        "#Deixar bem curtinho o corpo pra ir arrumando o código e testando os resultados. Pra sequência abaixo fazer mais sentido é bom que tenha alguma repetição de palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p03O8O4snNlL",
        "outputId": "63ec90c9-1f3f-41f6-824a-4d846446a33e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GASOLINA COMUM',\n",
              " 'MLTD203UXAZ CARTUCHO DE TONER PRETO 15K PAGINAS',\n",
              " 'HP RESERVATORIO DE RESIDUO DE TONER',\n",
              " 'UVA ITALIA',\n",
              " 'CLTC603LXAZ CARTUCHO DE TONER CIANO 10K PAGINAS',\n",
              " 'CARTUCHO DE TONER AMARELO 3.5K PAGINAS',\n",
              " 'CENOURA',\n",
              " 'CLTC506LXAZ CARTUCHO DE TONER CIANO 3.5K PAGINAS',\n",
              " 'PLACA LED ILUMINACAO',\n",
              " 'OLEO DIESEL B S10 ADITIVADO GRID']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 - Determinando as palavras muito frequentes "
      ],
      "metadata": {
        "id": "cqWJ3wiPuOee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for d in list(df3[\"DESCR\"]):\n",
        "    all_words += d.split()\n",
        "words_counts = pd.DataFrame(all_words).value_counts()\n",
        "print(\"Palavras mais frequentemente encontradas\")\n",
        "print(\" \".join([_[0] for _ in words_counts.index[:30]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IacZC5SuuTIb",
        "outputId": "559d1a7f-3bb3-41f6-8a29-99379c430bd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavras mais frequentemente encontradas\n",
            "- DE E PARA X COM 1 EM TIPO de A | DO FILTRO C/ DA MM 2 / PARAFUSO CABO Lote: P/ OLEO 100 Ed O MATERIAL 10 KG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "midICNFs5EsQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 - Seguindo com o tutorial do doc2vec (Que usa o modelo mais simples tf-idf)"
      ],
      "metadata": {
        "id": "tFniLr5d5GEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('- DE E PARA X COM EM TIPO de A | DO C/ DA / P/ Ed O'.split(' '))"
      ],
      "metadata": {
        "id": "WM51S5pavnLK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text_corpus]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "#Ignorei esse filtro pois com poucos exemplos iria cortar quase tudo\n",
        "processed_corpus = [[token for token in text if frequency[token] > 0] for text in texts]\n",
        "pprint.pprint(processed_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhZWW1bAwEDZ",
        "outputId": "d9b0f3ab-3b2d-4b60-f49b-dcea8ef3dc3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['gasolina', 'comum'],\n",
            " ['mltd203uxaz', 'cartucho', 'toner', 'preto', '15k', 'paginas'],\n",
            " ['hp', 'reservatorio', 'residuo', 'toner'],\n",
            " ['uva', 'italia'],\n",
            " ['cltc603lxaz', 'cartucho', 'toner', 'ciano', '10k', 'paginas'],\n",
            " ['cartucho', 'toner', 'amarelo', '3.5k', 'paginas'],\n",
            " ['cenoura'],\n",
            " ['cltc506lxaz', 'cartucho', 'toner', 'ciano', '3.5k', 'paginas'],\n",
            " ['placa', 'led', 'iluminacao'],\n",
            " ['oleo', 'diesel', 'b', 's10', 'aditivado', 'grid']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_corpus[0] = processed_corpus[0]+processed_corpus[0] #Forcei uma palavra repetida na descrição somente para ter um exemplo\n",
        "processed_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw0RuVx86Kr5",
        "outputId": "0e090ecc-6cdf-4eed-d750-3a92d9a1dfc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['gasolina', 'comum', 'gasolina', 'comum'],\n",
              " ['mltd203uxaz', 'cartucho', 'toner', 'preto', '15k', 'paginas'],\n",
              " ['hp', 'reservatorio', 'residuo', 'toner'],\n",
              " ['uva', 'italia'],\n",
              " ['cltc603lxaz', 'cartucho', 'toner', 'ciano', '10k', 'paginas'],\n",
              " ['cartucho', 'toner', 'amarelo', '3.5k', 'paginas'],\n",
              " ['cenoura'],\n",
              " ['cltc506lxaz', 'cartucho', 'toner', 'ciano', '3.5k', 'paginas'],\n",
              " ['placa', 'led', 'iluminacao'],\n",
              " ['oleo', 'diesel', 'b', 's10', 'aditivado', 'grid']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(processed_corpus)\n",
        "print(dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeBPOvNSx13o",
        "outputId": "3444ff6e-c6f5-4e37-eb94-a40fcccc27a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(29 unique tokens: ['comum', 'gasolina', '15k', 'cartucho', 'mltd203uxaz']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHt4VSMmz8W-",
        "outputId": "bf4d3086-3191-479a-b4d3-586bef1d2244"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'10k': 13,\n",
            " '15k': 2,\n",
            " '3.5k': 16,\n",
            " 'aditivado': 23,\n",
            " 'amarelo': 17,\n",
            " 'b': 24,\n",
            " 'cartucho': 3,\n",
            " 'cenoura': 18,\n",
            " 'ciano': 14,\n",
            " 'cltc506lxaz': 19,\n",
            " 'cltc603lxaz': 15,\n",
            " 'comum': 0,\n",
            " 'diesel': 25,\n",
            " 'gasolina': 1,\n",
            " 'grid': 26,\n",
            " 'hp': 8,\n",
            " 'iluminacao': 20,\n",
            " 'italia': 11,\n",
            " 'led': 21,\n",
            " 'mltd203uxaz': 4,\n",
            " 'oleo': 27,\n",
            " 'paginas': 5,\n",
            " 'placa': 22,\n",
            " 'preto': 6,\n",
            " 'reservatorio': 9,\n",
            " 'residuo': 10,\n",
            " 's10': 28,\n",
            " 'toner': 7,\n",
            " 'uva': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
        "pprint.pprint(bow_corpus)\n",
        "#The first entry in each tuple corresponds to the ID of the token in the dictionary, the second corresponds to the count of this token."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cOGkzG0IwE",
        "outputId": "fc45d2a3-1754-4f2e-f5b5-d3cb491fecc0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 2), (1, 2)],\n",
            " [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
            " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
            " [(11, 1), (12, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (13, 1), (14, 1), (15, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (16, 1), (17, 1)],\n",
            " [(18, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (14, 1), (16, 1), (19, 1)],\n",
            " [(20, 1), (21, 1), (22, 1)],\n",
            " [(23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_doc = \"gasolina hp hp interaction uva\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)\n",
        "#Como interaction não existe no dicionário ele não insere o token "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk6euDKj01dM",
        "outputId": "d3b93640-675c-4e9f-e0ea-abaa60cfb076"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 1), (8, 2), (12, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "# train the model\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "# transform the \"system minors\" string\n",
        "words = \"gasolina hp CIANO\".lower().split()\n",
        "print(tfidf[dictionary.doc2bow(words)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE2mcb4y7B4v",
        "outputId": "33186dd0-a640-4e66-ac16-2165c0e86eda"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 0.633907694445084), (8, 0.633907694445084), (14, 0.44308246393491596)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 - Agora com word2vec\n",
        "Base: https://github.com/mfilipak/AFRAC_IA/blob/main/Analise_Descricao_versus_NCM.ipynb"
      ],
      "metadata": {
        "id": "Sl158ThSAh-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed=42\n",
        "text_corpus = random.sample(list(df3[\"DESCR\"]),50000)\n",
        "len(text_corpus)\n",
        "#Deixar bem curtinho o corpo pra ir arrumando o código e testando os resultados. Pra sequência abaixo fazer mais sentido é bom que tenha alguma repetição de palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_IsyuwD7usM",
        "outputId": "95d3aa31-df0a-442e-a67c-93f892d9776e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_corpus[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byEb5r5J9w8t",
        "outputId": "491422b0-4382-46df-be7d-87b0e46cc3e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PRENDEDOR UMBILICAL',\n",
              " 'ISR 1100 8 PORTS DUAL GE WAN ETHERNET RO',\n",
              " 'POTE VIDRO 2,2L',\n",
              " 'O (Des) Aprendizado de Si: transexualidades, interacao e cuidado em saude',\n",
              " 'NAPROXENO 500MG']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.1 - Tokeniza"
      ],
      "metadata": {
        "id": "Rollr6GpCGxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('- DE E PARA X COM EM TIPO de A | DO C/ DA / P/ Ed O'.split(' '))\n",
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text_corpus]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "#Ignorei esse filtro pois com poucos exemplos iria cortar quase tudo\n",
        "processed_corpus = [[token for token in text if frequency[token] > 0] for text in texts]\n",
        "pprint.pprint(processed_corpus[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA1glhML-9Rb",
        "outputId": "efb52885-7b7f-43e1-af62-7c5d3decd049"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['prendedor', 'umbilical'],\n",
            " ['isr', '1100', '8', 'ports', 'dual', 'ge', 'wan', 'ethernet', 'ro'],\n",
            " ['pote', 'vidro', '2,2l'],\n",
            " ['o',\n",
            "  '(des)',\n",
            "  'aprendizado',\n",
            "  'si:',\n",
            "  'transexualidades,',\n",
            "  'interacao',\n",
            "  'e',\n",
            "  'cuidado',\n",
            "  'em',\n",
            "  'saude'],\n",
            " ['naproxeno', '500mg']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.2 - Cria modelo"
      ],
      "metadata": {
        "id": "cAOROm-MCOck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(processed_corpus)]"
      ],
      "metadata": {
        "id": "ur-g2PINBt_p"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO: Não foi possível monitorar a loss durante o treino.\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "#import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "class callback(CallbackAny2Vec):\n",
        "    '''Callback to print loss after each epoch.'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        try:\n",
        "          loss = model.get_latest_training_loss()\n",
        "#          loss = model.running_training_loss()\n",
        "          print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        except:\n",
        "          print(f\"EXCEPTION - Epoch:{self.epoch}\")\n",
        "        self.epoch += 1\n",
        "\n",
        "#model = Word2Vec(common_texts, size=100, window=5, min_count=1, \n",
        "#                 compute_loss=True, callbacks=[callback()])"
      ],
      "metadata": {
        "id": "d1KwTqnnMuE3"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para 5000 itens e 200 epochs leva cerca de 2min\n",
        "#Para 50000 e 10 epochs cerca de 1 minuto\n",
        "model = Doc2Vec(tagged_data, vector_size = 50, window = 2, min_count = 1, epochs = 50, compute_loss=True, callbacks=[callback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "collapsed": true,
        "id": "Xh3bY1DqCRZP",
        "outputId": "6cd6a61b-9e39-49f9-9db7-c7f87f329479"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-b9bf756a4da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Para 5000 itens e 200 epochs leva cerca de 2min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Para 50000 e 10 epochs cerca de 1 minuto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, corpus_file, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try an iterator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m             self.train(\n\u001b[1;32m    613\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         self.trainables.prepare_weights(\n\u001b[0;32m-> 1172\u001b[0;31m             self.hs, self.negative, self.wv, self.docvecs, update=update)\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_vocab_from_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[0;34m(self, hs, negative, wv, docvecs, update)\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;31m# set initial input/projection and hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv, docvecs, vocabulary)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc2VecTrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_doc_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv)\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m             \u001b[0;31m# construct deterministic seed from word AND seed argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeded_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mseeded_vector\u001b[0;34m(self, seed_string, vector_size)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;34m\"\"\"Get a random vector (but deterministic by seed_string).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0;31m# Note: built-in hash() may vary by Python version or even (in Py3.x) per launch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         \u001b[0monce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ [k,model.wv.vocab[k]] for k in list(model.wv.vocab.keys())[:10] ] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM43FAGoDO6q",
        "outputId": "da26b496-7cad-4276-d0a7-febb173a527d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['prendedor', <gensim.models.keyedvectors.Vocab at 0x7f9f299c7c10>],\n",
              " ['umbilical', <gensim.models.keyedvectors.Vocab at 0x7f9f299c6210>],\n",
              " ['isr', <gensim.models.keyedvectors.Vocab at 0x7f9f29992d90>],\n",
              " ['1100', <gensim.models.keyedvectors.Vocab at 0x7f9f299b1810>],\n",
              " ['8', <gensim.models.keyedvectors.Vocab at 0x7f9f299b1550>],\n",
              " ['ports', <gensim.models.keyedvectors.Vocab at 0x7f9f299b1f10>],\n",
              " ['dual', <gensim.models.keyedvectors.Vocab at 0x7f9f299baf50>],\n",
              " ['ge', <gensim.models.keyedvectors.Vocab at 0x7f9f299ba0d0>],\n",
              " ['wan', <gensim.models.keyedvectors.Vocab at 0x7f9f299b1e50>],\n",
              " ['ethernet', <gensim.models.keyedvectors.Vocab at 0x7f9f299b1e10>]]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('banana')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jsnLVUgChD2",
        "outputId": "2dce789e-b2a3-435d-a691-ed856f119f53"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nanica-', 0.8730553984642029),\n",
              " ('classificacao', 0.8634437918663025),\n",
              " ('comprida', 0.8621338605880737),\n",
              " ('nanica/caturra', 0.8611175417900085),\n",
              " ('coruda', 0.8578562140464783),\n",
              " ('sacolao', 0.8536108732223511),\n",
              " ('curuda', 0.8531852960586548),\n",
              " ('1561', 0.8520442247390747),\n",
              " ('outros/doce', 0.8511369228363037),\n",
              " ('catura', 0.8500596880912781)]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_doc = word_tokenize(\"Água mineral\".lower())\n",
        "test_doc_vector = model.infer_vector(test_doc)\n",
        "model.docvecs.most_similar(positive = [test_doc_vector])\n",
        "test = model.docvecs.most_similar(positive = [test_doc_vector])\n",
        "#print_res(processed_corpus, df, test)"
      ],
      "metadata": {
        "id": "AzfsRRNhD1DU"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViFf2ddLD9Bl",
        "outputId": "9349e160-d957-49dc-8b76-33bfea75e920"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7884, 0.922605574131012),\n",
              " (31756, 0.9202933311462402),\n",
              " (38569, 0.9166479110717773),\n",
              " (5187, 0.9087568521499634),\n",
              " (46429, 0.9066520929336548),\n",
              " (13935, 0.9062210321426392),\n",
              " (1422, 0.9057298898696899),\n",
              " (22233, 0.9016014337539673),\n",
              " (31421, 0.9009100794792175),\n",
              " (4908, 0.9001277685165405)]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[[f, text_corpus[i]] for i,f in test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa15LTKvHRaz",
        "outputId": "986954db-f5c0-420e-862b-0277707cd192"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.922605574131012, 'OLEO SINTETICO 5W30'],\n",
              " [0.9202933311462402, 'FILTRO OLEO LUBRIFICANTE MOTOR'],\n",
              " [0.9166479110717773, 'Oleo lubrificante motor'],\n",
              " [0.9087568521499634, 'AGUA MINERAL IGUATU 20 LITROS'],\n",
              " [0.9066520929336548, 'DETERGENTE LIQUIDO NEUTRO 5L'],\n",
              " [0.9062210321426392, 'CREME DE LEITE'],\n",
              " [0.9057298898696899, 'AGUA SANITARIA DACLOR'],\n",
              " [0.9016014337539673, 'AGUA MINERAL 20 LT'],\n",
              " [0.9009100794792175, 'SORVETE SABOR MORANGO'],\n",
              " [0.9001277685165405, 'CARGA DE GAS REFRIGERANTE']]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"w2vec_pdt_50000\")"
      ],
      "metadata": {
        "id": "PX0pz7oFHtmi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Word2Vec.load(\"w2vec_pdt_50000\")"
      ],
      "metadata": {
        "id": "C5z2H46_JT8x"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_doc_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsJ8_Vy6KCC_",
        "outputId": "d3b6bd9f-9ada-4e6a-8b11-dac2b15c3813"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03000239, -0.15835182, -0.04647423,  0.14115329, -0.07367107,\n",
              "        0.03759604, -0.07620105, -0.09130988,  0.16599672,  0.05553066,\n",
              "        0.16873552, -0.17667705,  0.03919876,  0.11087141, -0.02132544,\n",
              "        0.23486793, -0.04122794,  0.1987489 ,  0.02941088,  0.09548191,\n",
              "       -0.1203687 , -0.11891499,  0.04286085, -0.21720862, -0.00236382,\n",
              "       -0.01745856,  0.13263069, -0.04381289,  0.07859285, -0.15365988,\n",
              "       -0.09684193, -0.06030251, -0.08885856, -0.17635266, -0.02134677,\n",
              "       -0.03131416,  0.04445688,  0.03472563, -0.08625112,  0.22030483,\n",
              "        0.02256696,  0.03918594,  0.07095011,  0.00038026,  0.09367124,\n",
              "        0.03978023,  0.041751  ,  0.0447984 , -0.04299439,  0.01537837],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.infer_vector(test_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnx1PIwgKV_b",
        "outputId": "181818ab-cf27-4f25-c74a-681ba0f36f06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01882276, -0.04699792,  0.03210271, -0.00119155, -0.02704529,\n",
              "        0.01287987,  0.02143767, -0.00590753, -0.03285823, -0.03793808,\n",
              "       -0.03860652,  0.00632336,  0.0052625 ,  0.02911218,  0.00118628,\n",
              "        0.01616548, -0.01733688,  0.0238259 ,  0.01753198, -0.03056025,\n",
              "        0.00812793, -0.00881012, -0.0065726 ,  0.00220483,  0.04933191,\n",
              "        0.03196358, -0.00600734,  0.01025085,  0.02780269,  0.01065063,\n",
              "       -0.01800748,  0.03328613,  0.03862325, -0.01533649,  0.00803987,\n",
              "       -0.00407112, -0.00162246,  0.0198715 , -0.01594796,  0.03032946,\n",
              "        0.01261197,  0.01210154,  0.05338154,  0.03924512, -0.00113517,\n",
              "        0.01921435, -0.02555567,  0.00249498, -0.02810187,  0.0132193 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2XIpQZmxKfhQ"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}