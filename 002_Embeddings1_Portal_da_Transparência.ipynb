{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "002 - Embeddings1 - Portal da Transparência.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9KpmhnOAUaAavDN5SpHw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfilipak/AFRAC_IA/blob/main/002_Embeddings1_Portal_da_Transpar%C3%AAncia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM CONSTRUÇÃO"
      ],
      "metadata": {
        "id": "ANdfGpMVsm6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento 002\n",
        "##Objetivo: Experimentos com word embeddings usando como corpo o campo de descrição do dataset público do portal da transparência.\n",
        "###Descrição: Experimentos iniciais para criação e visualização de word embeddings"
      ],
      "metadata": {
        "id": "d5G4UIQLkvr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dica: No COLAB Use CTRL SPACE ao invés de TAB para \"autocompletar\". Ex:pd.re [CTRL SPACE] vai mostrar uma lista contendo as funções e atributos que começam com pd.re (como read_csv, ...) "
      ],
      "metadata": {
        "id": "F9TFhfPOld7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pprint"
      ],
      "metadata": {
        "id": "Nvzp4RpDlHTq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 - Carga do dataset"
      ],
      "metadata": {
        "id": "nHAJmE8HtX7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Copia os dados das NFEs do portal da cidadância pro drive virtual.\n",
        "import requests  \n",
        "file_url = \"https://raw.githubusercontent.com//mfilipak/AFRAC_IA/main/DATASET/202201_NFe_NotaFiscalItem.zip\"\n",
        "r = requests.get(file_url, stream = True) \n",
        "\n",
        "with open(\"portal.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)\n",
        "\n",
        "DATA_FILE = \"portal.zip\"\n",
        "df = pd.read_csv(DATA_FILE, encoding=\"CP1252\",sep=\";\")\n",
        "print(\"O dataframe completo contém:\",len(df),\"linhas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tBOpT5elhBD",
        "outputId": "c8d210b3-3989-4694-9a58-abdf7a11f339"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dataframe completo contém: 324056 linhas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df[['DATA EMISSÃO','DESCRIÇÃO DO PRODUTO/SERVIÇO', 'CÓDIGO NCM/SH', 'CFOP']]\n",
        "df3.columns = [\"DATA\", \"DESCR\", \"NCM\", \"CFOP\"]\n",
        "df3 = df3[df3[\"NCM\"]!=-1] #Filtrando NCMs = -1\n",
        "\n",
        "text_lengths = np.array([len(_) for _ in df3['DESCR']])\n",
        "df3 = df3[text_lengths>=3]\n",
        "\n",
        "#Caso queira eliminar as repetições rodar a linha abaixo\n",
        "df3 = df3.drop_duplicates(subset=[\"DESCR\"])"
      ],
      "metadata": {
        "id": "8IVtFSawlr_T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 - Carga do text corpus"
      ],
      "metadata": {
        "id": "fkOffymdtdem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No jargão do doc2vec, cada descrição é um document e o conjunto de docs um corpus\n",
        "#Link: https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html#sphx-glr-auto-examples-core-run-core-concepts-py\n",
        "random.seed(42)\n",
        "#text_corpus = random.sample(list(df3[\"DESCR\"]), 100)\n",
        "text_corpus = random.sample(list(df3[\"DESCR\"][:30]), 10)\n",
        "text_corpus\n",
        "#Deixar bem curtinho o corpo pra ir arrumando o código e testando os resultados. Pra sequência abaixo fazer mais sentido é bom que tenha alguma repetição de palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p03O8O4snNlL",
        "outputId": "26990168-5b8b-4983-c7ef-e7d95f439496"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GASOLINA COMUM',\n",
              " 'MLTD203UXAZ CARTUCHO DE TONER PRETO 15K PAGINAS',\n",
              " 'HP RESERVATORIO DE RESIDUO DE TONER',\n",
              " 'UVA ITALIA',\n",
              " 'CLTC603LXAZ CARTUCHO DE TONER CIANO 10K PAGINAS',\n",
              " 'CARTUCHO DE TONER AMARELO 3.5K PAGINAS',\n",
              " 'CENOURA',\n",
              " 'CLTC506LXAZ CARTUCHO DE TONER CIANO 3.5K PAGINAS',\n",
              " 'PLACA LED ILUMINACAO',\n",
              " 'OLEO DIESEL B S10 ADITIVADO GRID']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 - Determinando as palavras muito frequentes "
      ],
      "metadata": {
        "id": "cqWJ3wiPuOee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "for d in list(df3[\"DESCR\"]):\n",
        "    all_words += d.split()\n",
        "words_counts = pd.DataFrame(all_words).value_counts()\n",
        "print(\"Palavras mais frequentemente encontradas\")\n",
        "print(\" \".join([_[0] for _ in words_counts.index[:30]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IacZC5SuuTIb",
        "outputId": "3b9f197a-d630-4839-be9d-fe43815a4aa1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavras mais frequentemente encontradas\n",
            "- DE E PARA X COM 1 EM TIPO de A | DO FILTRO C/ DA MM 2 / PARAFUSO CABO Lote: P/ OLEO 100 Ed O MATERIAL 10 KG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "midICNFs5EsQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 - Seguindo com o tutorial do doc2vec (Que usa o modelo mais simples tf-idf)"
      ],
      "metadata": {
        "id": "tFniLr5d5GEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('- DE E PARA X COM EM TIPO de A | DO C/ DA / P/ Ed O'.split(' '))"
      ],
      "metadata": {
        "id": "WM51S5pavnLK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text_corpus]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "#Ignorei esse filtro pois com poucos exemplos iria cortar quase tudo\n",
        "processed_corpus = [[token for token in text if frequency[token] > 0] for text in texts]\n",
        "pprint.pprint(processed_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhZWW1bAwEDZ",
        "outputId": "53caad7e-9ab2-4007-afed-48dc826da6b8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['gasolina', 'comum'],\n",
            " ['mltd203uxaz', 'cartucho', 'toner', 'preto', '15k', 'paginas'],\n",
            " ['hp', 'reservatorio', 'residuo', 'toner'],\n",
            " ['uva', 'italia'],\n",
            " ['cltc603lxaz', 'cartucho', 'toner', 'ciano', '10k', 'paginas'],\n",
            " ['cartucho', 'toner', 'amarelo', '3.5k', 'paginas'],\n",
            " ['cenoura'],\n",
            " ['cltc506lxaz', 'cartucho', 'toner', 'ciano', '3.5k', 'paginas'],\n",
            " ['placa', 'led', 'iluminacao'],\n",
            " ['oleo', 'diesel', 'b', 's10', 'aditivado', 'grid']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_corpus[0] = processed_corpus[0]+processed_corpus[0] #Forcei uma palavra repetida na descrição somente para ter um exemplo\n",
        "processed_corpus"
      ],
      "metadata": {
        "id": "Dw0RuVx86Kr5",
        "outputId": "3ca5874d-a1f5-450a-b47f-4f0de8a46097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['gasolina', 'comum', 'gasolina', 'comum'],\n",
              " ['mltd203uxaz', 'cartucho', 'toner', 'preto', '15k', 'paginas'],\n",
              " ['hp', 'reservatorio', 'residuo', 'toner'],\n",
              " ['uva', 'italia'],\n",
              " ['cltc603lxaz', 'cartucho', 'toner', 'ciano', '10k', 'paginas'],\n",
              " ['cartucho', 'toner', 'amarelo', '3.5k', 'paginas'],\n",
              " ['cenoura'],\n",
              " ['cltc506lxaz', 'cartucho', 'toner', 'ciano', '3.5k', 'paginas'],\n",
              " ['placa', 'led', 'iluminacao'],\n",
              " ['oleo', 'diesel', 'b', 's10', 'aditivado', 'grid']]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(processed_corpus)\n",
        "print(dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeBPOvNSx13o",
        "outputId": "61803289-de8c-4249-e411-6847518a5c8d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(29 unique tokens: ['comum', 'gasolina', '15k', 'cartucho', 'mltd203uxaz']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHt4VSMmz8W-",
        "outputId": "07a630af-a918-4753-a8f1-5d5b686d26af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'10k': 13,\n",
            " '15k': 2,\n",
            " '3.5k': 16,\n",
            " 'aditivado': 23,\n",
            " 'amarelo': 17,\n",
            " 'b': 24,\n",
            " 'cartucho': 3,\n",
            " 'cenoura': 18,\n",
            " 'ciano': 14,\n",
            " 'cltc506lxaz': 19,\n",
            " 'cltc603lxaz': 15,\n",
            " 'comum': 0,\n",
            " 'diesel': 25,\n",
            " 'gasolina': 1,\n",
            " 'grid': 26,\n",
            " 'hp': 8,\n",
            " 'iluminacao': 20,\n",
            " 'italia': 11,\n",
            " 'led': 21,\n",
            " 'mltd203uxaz': 4,\n",
            " 'oleo': 27,\n",
            " 'paginas': 5,\n",
            " 'placa': 22,\n",
            " 'preto': 6,\n",
            " 'reservatorio': 9,\n",
            " 'residuo': 10,\n",
            " 's10': 28,\n",
            " 'toner': 7,\n",
            " 'uva': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
        "pprint.pprint(bow_corpus)\n",
        "#The first entry in each tuple corresponds to the ID of the token in the dictionary, the second corresponds to the count of this token."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cOGkzG0IwE",
        "outputId": "37b79224-785f-467b-f975-6baf0895f389"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 2), (1, 2)],\n",
            " [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
            " [(7, 1), (8, 1), (9, 1), (10, 1)],\n",
            " [(11, 1), (12, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (13, 1), (14, 1), (15, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (16, 1), (17, 1)],\n",
            " [(18, 1)],\n",
            " [(3, 1), (5, 1), (7, 1), (14, 1), (16, 1), (19, 1)],\n",
            " [(20, 1), (21, 1), (22, 1)],\n",
            " [(23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_doc = \"gasolina hp hp interaction uva\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)\n",
        "#Como interaction não existe no dicionário ele não insere o token "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk6euDKj01dM",
        "outputId": "af837c40-cbf7-4379-fed3-a87b709760c5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 1), (8, 2), (12, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "# train the model\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "# transform the \"system minors\" string\n",
        "words = \"gasolina hp CIANO\".lower().split()\n",
        "print(tfidf[dictionary.doc2bow(words)])"
      ],
      "metadata": {
        "id": "iE2mcb4y7B4v",
        "outputId": "8f5cc596-a685-46c1-e9b4-b02264485aa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 0.633907694445084), (8, 0.633907694445084), (14, 0.44308246393491596)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 - Agora com word2vec\n",
        "Base: https://github.com/mfilipak/AFRAC_IA/blob/main/Analise_Descricao_versus_NCM.ipynb"
      ],
      "metadata": {
        "id": "Sl158ThSAh-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed=42\n",
        "text_corpus = random.sample(list(df3[\"DESCR\"]),5000)\n",
        "len(text_corpus)\n",
        "#Deixar bem curtinho o corpo pra ir arrumando o código e testando os resultados. Pra sequência abaixo fazer mais sentido é bom que tenha alguma repetição de palavras"
      ],
      "metadata": {
        "id": "N_IsyuwD7usM",
        "outputId": "abd1fdd4-0b63-4ac4-9479-e7dab10bde02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_corpus[:5]"
      ],
      "metadata": {
        "id": "byEb5r5J9w8t",
        "outputId": "7adc15cf-adb8-43eb-8ce8-5d231274df3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TUBO DE CONCRETO 100 CM MF PA 2',\n",
              " 'RETRATO DE DORIAN GRAY, O - POCKET',\n",
              " 'HD LITE-ON NV-ME M2 256GB',\n",
              " 'PAPEL ALUMINIO - COMPRIMENTO DO ROLO 7,50 M, LARGURA 45 CM.',\n",
              " 'SUPORTE - ELETROVENTILADOR']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.1 - Tokeniza"
      ],
      "metadata": {
        "id": "Rollr6GpCGxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('- DE E PARA X COM EM TIPO de A | DO C/ DA / P/ Ed O'.split(' '))\n",
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text_corpus]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "#Ignorei esse filtro pois com poucos exemplos iria cortar quase tudo\n",
        "processed_corpus = [[token for token in text if frequency[token] > 0] for text in texts]\n",
        "pprint.pprint(processed_corpus[:5])"
      ],
      "metadata": {
        "id": "eA1glhML-9Rb",
        "outputId": "ad9c58c4-d879-4484-9339-08aff6210d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['tubo', 'concreto', '100', 'cm', 'mf', 'pa', '2'],\n",
            " ['retrato', 'dorian', 'gray,', 'o', 'pocket'],\n",
            " ['hd', 'lite-on', 'nv-me', 'm2', '256gb'],\n",
            " ['papel',\n",
            "  'aluminio',\n",
            "  'comprimento',\n",
            "  'do',\n",
            "  'rolo',\n",
            "  '7,50',\n",
            "  'm,',\n",
            "  'largura',\n",
            "  '45',\n",
            "  'cm.'],\n",
            " ['suporte', 'eletroventilador']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.2 - Cria modelo"
      ],
      "metadata": {
        "id": "cAOROm-MCOck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(processed_corpus)]"
      ],
      "metadata": {
        "id": "ur-g2PINBt_p"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xh3bY1DqCRZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}