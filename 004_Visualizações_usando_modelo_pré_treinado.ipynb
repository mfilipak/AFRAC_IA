{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "004 - Visualizações usando modelo pré-treinado.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSDJyuEpSPWK7AVvL0KUYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfilipak/AFRAC_IA/blob/main/004_Visualiza%C3%A7%C3%B5es_usando_modelo_pr%C3%A9_treinado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM CONSTRUÇÃO"
      ],
      "metadata": {
        "id": "Hww__Aa1pQvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento 004\n",
        "##Objetivo: Experimentos de visualização de word embeddings carregando modelo(s) treinado(s) no Experimento 002.\n",
        "###Descrição: Experimentos iniciais para criação e visualização de word embeddings<br>\n",
        "Dica: No COLAB Use CTRL SPACE ao invés de TAB para \"autocompletar\". Ex:pd.re [CTRL SPACE] vai mostrar uma lista contendo as funções e atributos que começam com pd.re (como read_csv, ...) "
      ],
      "metadata": {
        "id": "tKa_HwaTpdiZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ospvEHQOmWWC"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCnlUOf3p_Iw",
        "outputId": "2f957823-c4be-4077-acee-56eba26de210"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copia os dados das NFEs do portal da cidadância pro drive virtual.\n",
        "import requests  \n",
        "file_url = \"https://raw.githubusercontent.com//mfilipak/AFRAC_IA/main/MODELS/w2vec_pdt_5000\"\n",
        "r = requests.get(file_url, stream = True) \n",
        "\n",
        "with open(\"w2vec_pdt_5000\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)\n"
      ],
      "metadata": {
        "id": "IVdDhR8bq5vD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caso o treino tenha sido feito chamando a classe callback ela precisa ser declarada para permitir a carga\n",
        "\n",
        "#TO DO: Não foi possível monitorar a loss durante o treino.\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "#import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "class callback(CallbackAny2Vec):\n",
        "    '''Callback to print loss after each epoch.'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        try:\n",
        "          loss = model.running_training_loss\n",
        "          print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        except:\n",
        "          print(f\"EXCEPTION - Epoch:{self.epoch}\")\n",
        "        self.epoch += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "3OMe_B5orRk9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load(\"w2vec_pdt_5000\",  )"
      ],
      "metadata": {
        "id": "5SCJAUeEqx0E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.wv.vocab.keys())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcitzKEbwPoQ",
        "outputId": "6522d8e6-ea50-4640-de14-6ee0f650892b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['maza',\n",
              " 'diluente',\n",
              " 'p/',\n",
              " 'epoxi',\n",
              " 'dp-003',\n",
              " '5',\n",
              " 'l',\n",
              " 'coletor',\n",
              " 'mat.perfuro',\n",
              " 'cortantes']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_doc = word_tokenize(\"banana prata\".lower())\n",
        "test_doc_vector = model.infer_vector(test_doc)\n",
        "test = model.docvecs.most_similar(positive = [test_doc_vector])\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAQ1o8yvwLL_",
        "outputId": "75b506e9-ef44-4432-bfd0-1003784aa53d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2197, 0.8462918400764465),\n",
              " (4738, 0.8331982493400574),\n",
              " (1069, 0.8303892016410828),\n",
              " (840, 0.8127132654190063),\n",
              " (304, 0.8011035919189453),\n",
              " (2209, 0.7637394666671753),\n",
              " (833, 0.7607715725898743),\n",
              " (2478, 0.7427284717559814),\n",
              " (4366, 0.7394019365310669),\n",
              " (627, 0.7328137159347534)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, _ in test:\n",
        "  target =  model.docvecs[i]\n",
        "  print(i, target.dot(test_doc_vector)/np.linalg.norm(target)/np.linalg.norm(test_doc_vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Wve7MQBq61",
        "outputId": "7a071828-adb9-4f5e-a4aa-8922a733b742"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4383 0.6494874\n",
            "4650 0.5587584\n",
            "4088 0.54741865\n",
            "407 0.5371437\n",
            "1184 0.53489846\n",
            "1461 0.5167127\n",
            "1288 0.51626986\n",
            "4725 0.51539415\n",
            "903 0.5106894\n",
            "1934 0.5100722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Esse trecho de código copia o text_corpus do jeito que foi feito o treino.\n",
        "#Posteriormente, vamos fazer com que isso não seja relevante montando all_vectors a partir da inferência\n",
        "import requests  \n",
        "file_url = \"https://raw.githubusercontent.com//mfilipak/AFRAC_IA/main/DATASET/202201_NFe_NotaFiscalItem.zip\"\n",
        "r = requests.get(file_url, stream = True) \n",
        "\n",
        "with open(\"portal.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)\n",
        "\n",
        "DATA_FILE = \"portal.zip\"\n",
        "df = pd.read_csv(DATA_FILE, encoding=\"CP1252\",sep=\";\")\n",
        "print(\"O dataframe completo contém:\",len(df),\"linhas\")\n",
        "df3 = df[['DATA EMISSÃO','DESCRIÇÃO DO PRODUTO/SERVIÇO', 'CÓDIGO NCM/SH', 'CFOP']]\n",
        "df3.columns = [\"DATA\", \"DESCR\", \"NCM\", \"CFOP\"]\n",
        "df3 = df3[df3[\"NCM\"]!=-1] #Filtrando NCMs = -1\n",
        "\n",
        "text_lengths = np.array([len(_) for _ in df3['DESCR']])\n",
        "df3 = df3[text_lengths>=3]\n",
        "\n",
        "#Caso queira eliminar as repetições rodar a linha abaixo\n",
        "df3 = df3.drop_duplicates(subset=[\"DESCR\"])\n",
        "random.seed(42)\n",
        "text_corpus = random.sample(list(df3[\"DESCR\"]),5000)\n",
        "len(text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka82sge26glM",
        "outputId": "320cfa3d-3566-42cb-8ef1-eee29c50081f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O dataframe completo contém: 324056 linhas\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors = model.docvecs.vectors_docs\n",
        "\n",
        "test_doc = word_tokenize(\"banana prata\".lower())\n",
        "test_doc_vector = model.infer_vector(test_doc)\n",
        "\n",
        "cos_distances = all_vectors.dot(test_doc_vector)/np.linalg.norm(all_vectors, axis=-1)/np.linalg.norm(test_doc_vector)\n",
        "for i in np.argsort(cos_distances)[::-1][:10]:\n",
        "  print(text_corpus[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Sd02YzDeHt",
        "outputId": "e2878e1a-3090-4342-8a1f-9bbde8e1e860"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banana comprida\n",
            "FRUTA IN NATURA BANANA PRATA\n",
            "BANANA NANICA/CATURRA CLIM PRIM\n",
            "BANANA ESPECIE COMPRIDA\n",
            "BANANA NANICA\n",
            "OUTROS/BANANA PRATA\n",
            "FRUTA IN NATURA, TIPO MELAO, ESPECIE AMARELO.\n",
            "FARINHA DE ROSCA - PULLMAN\n",
            "ALHO NATURAL CABEÇA BRANCA\n",
            "DOCE DE BANANA COM 50UND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "new_text_corpus = random.sample(list(df3[\"DESCR\"]),5000)\n",
        "len(new_text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcEnhsq7Fv7d",
        "outputId": "d07b4e99-bca5-490d-a947-6728df04b964"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors = model.docvecs.vectors_docs\n",
        "\n",
        "test_doc = word_tokenize(\"banana prata\".lower())\n",
        "test_doc_vector = model.infer_vector(test_doc)\n",
        "\n",
        "cos_distances = all_vectors.dot(test_doc_vector)/np.linalg.norm(all_vectors, axis=-1)/np.linalg.norm(test_doc_vector)\n",
        "for i in np.argsort(cos_distances)[::-1][:10]:\n",
        "  print(new_text_corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkoO56KnG737",
        "outputId": "0a434015-b803-40f5-cdc3-6a7c6ca57486"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IOGURTE NINHO MACA E BANANA 170 G\n",
            "PLACA LCP RADIO D LAT 2,7MM 6F L: 160032879-025 ANVISA N : 80082910118\n",
            "ABRAÇADEIRA, MATERIAL PLÁSTICO, COMPRIMENTO TOTAL 110 MM, LARGURA 2,50 MM,APLICAÇÃO\n",
            "FORMA TUBO PUDIM/BOLO\n",
            "RABADA\n",
            "FECH PADO TRIO QUADRA ROS 701-80 MP16500 CR\n",
            "FONTE 24VCC BIVOLT SAIDA DUPLA 3A 72W DIN CERTIFICADA\n",
            "OUTROS OLEOS LUBRIFICANTES AUTOMOTIVOS                                     - Item 5\n",
            "INTRINSECA | SPRINT: O METODO USADO NO GOOGLE PARA TESTAR E APLICAR NOVAS IDEIAS EM APENAS CINCO DIAS | Ed: 12017\n",
            "CIL MESTRE FREIO REMANOFATURADO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoplist = set('- DE E PARA X COM EM TIPO de A | DO C/ DA / P/ Ed O'.split(' '))\n",
        "# Lowercase each document, split it by white space and filter out stopwords\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in new_text_corpus]\n",
        "\n",
        "# Count word frequencies\n",
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "# Only keep words that appear more than once\n",
        "#Ignorei esse filtro pois com poucos exemplos iria cortar quase tudo\n",
        "processed_corpus = [[token for token in text if frequency[token] > 0] for text in texts]\n",
        "pprint.pprint(processed_corpus[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uReJlfQPG-db",
        "outputId": "33880e08-2e2b-4b52-c587-7b35c517874e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['vavula', 'escape', 'tr4', '2010/...'],\n",
            " ['foice', 'rocadeira', 'tipo', 'l,', 'c/', 'cabo,', '1,2m'],\n",
            " ['sinapi', '4721', 'brita', '1', '(posto', 'jazida)'],\n",
            " ['componente',\n",
            "  'cortador',\n",
            "  'legumes,',\n",
            "  'tipo',\n",
            "  'manual,',\n",
            "  'tipo',\n",
            "  'acessório',\n",
            "  'lâmina,',\n",
            "  'material',\n",
            "  'aço',\n",
            "  'inoxidável'],\n",
            " ['fresa', 'canulada', '06,0', 'mm.', 'rms.80804050147']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors = []\n",
        "for pc in processed_corpus[:]:\n",
        "  all_vectors += [model.infer_vector(pc)]\n",
        "all_vectors = np.array(all_vectors)\n",
        "all_vectors.shape"
      ],
      "metadata": {
        "id": "CTbcxk3dHWID"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all_vectors = model.docvecs.vectors_docs\n",
        "\n",
        "test_doc = word_tokenize(\"erva mate\".lower())\n",
        "test_doc_vector = model.infer_vector(test_doc)\n",
        "\n",
        "cos_distances = all_vectors.dot(test_doc_vector)/np.linalg.norm(all_vectors, axis=-1)/np.linalg.norm(test_doc_vector)\n",
        "for i in np.argsort(cos_distances)[::-1][:10]:\n",
        "  print(new_text_corpus[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db-lhr9xIJU6",
        "outputId": "bd366a8b-c676-4a15-bbd4-91537da04e55"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHA ERVA CIDREIRA\n",
            "CHA FRUTAS CITRICAS CHILENO ECONOMICO CAIXA 10G/10 SACHES\n",
            "ERVA MATE 1KG\n",
            "FOSVITA 250G\n",
            "2I BIOLOGICAL TEST - VAPOR - 3H - CX. C/ 50 UN.\n",
            "milho, tipo: grão, aplicação: mungunzá (canjica) 500G\n",
            "COLHER CHA BASIC - GOURMET MIX GX4070\n",
            "TUBO DE CENTRIFUGA 15ML CX 500 UN\n",
            "CAFE BICO PREMIUM SUPERIOR 500G LIC\n",
            "MOSTARDA 250G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fBRBvOWmILDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}